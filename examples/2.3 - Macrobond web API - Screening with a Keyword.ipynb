{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 - Macrobond web API - Screening with a Keyword\n",
    "\n",
    "*Performing coverage checks based on a keyword*\n",
    "\n",
    "This notebook aims to provide examples of how to use Macrobond's web API call methods as well as insights on the key attributes used to display the output in an understandable format.\n",
    "\n",
    "We will focus here on using the Search method based on a **keyword** filter. This helps you build a list of time series potentially relating to a common theme.\n",
    "\n",
    "*The examples uses the Web API, but you can chose to use the desktop COM API and get the same result. Full error handling is omitted for brevity*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from macrobond_financial.web import WebClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Get the data - Keyword: Government Securities Auctions\n",
    "\n",
    "Note that we are using here the Search endpoint with filters on keyword `text=Government Securities Auctions` and `Frequency=daily` time series in this example.\n",
    "\n",
    "Feel free to refer to https://api.macrobondfinancial.com/swagger/index.html to get the comprehensive list of web API endpoints and parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Visualising the data\n",
    "Let's evaluate Macrobond's coverage for daily time series related to government securities auctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WebClient() as api:\n",
    "    data_frame = api.entity_search(\n",
    "        text=\"Government Securities Auctions\",\n",
    "        entity_types=\"TimeSeries\",\n",
    "        must_have_values={\"Frequency\": \"daily\"},\n",
    "        include_discontinued=False,\n",
    "    ).to_pd_data_frame()[\n",
    "        [\n",
    "            \"Name\",\n",
    "            \"FullDescription\",\n",
    "            \"Description\",\n",
    "            \"Region\",\n",
    "            \"Category\",\n",
    "            \"Frequency\",\n",
    "            \"Source\",\n",
    "            \"Class\",\n",
    "            \"PriceType\",\n",
    "        ]\n",
    "    ]\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make sense of the attribute PriceType\n",
    "\n",
    "We will use here the metadata endpoint from the web API as detailed in the notebook **1.1 - Macrobond web API - Metadata Navigation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WebClient() as api:\n",
    "    data_frame = api.metadata_get_attribute_information(\"PriceType\")[0].to_pd_data_frame()\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the PriceType uses values from list and is not a free text attribute, let's have a look at its values to be used later as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WebClient() as api:\n",
    "    df3 = api.metadata_list_values(\"PriceType\").to_pd_data_frame()[\n",
    "        [\"value\", \"description\", \"comment\"]\n",
    "    ]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we get a sense of potential groupings we can achieve thanks to the metadata, let's manipulate the ones that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with WebClient() as api:\n",
    "    data_frame = api.entity_search(\n",
    "        text=\"Government Securities Auctions\",\n",
    "        entity_types=\"TimeSeries\",\n",
    "        must_have_values={\"Frequency\": \"daily\"},\n",
    "        include_discontinued=False,\n",
    "    ).to_pd_data_frame()[\n",
    "        [\n",
    "            \"Name\",\n",
    "            \"FullDescription\",\n",
    "            \"Description\",\n",
    "            \"Region\",\n",
    "            \"Category\",\n",
    "            \"Frequency\",\n",
    "            \"Source\",\n",
    "            \"Class\",\n",
    "            \"PriceType\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "data_frame[\"RegionString\"] = data_frame[\"Region\"].apply(\n",
    "    lambda x: \"\" if pandas.isna(x) else \", \".join(map(str, x))\n",
    ")\n",
    "\n",
    "# Need to account for NaN values before converting to a string\n",
    "data_frame[\"PriceTypeS\"] = data_frame[\"PriceType\"].fillna(\"\")\n",
    "data_frame[\"PriceTypeString\"] = data_frame[\"PriceTypeS\"].apply(lambda x: \", \".join(map(str, x)))\n",
    "\n",
    "# Mapping the PriceType to its descriptions\n",
    "mapping = dict(df3[[\"value\", \"description\"]].values)\n",
    "data_frame[\"PriceTypeD\"] = data_frame.PriceTypeString.map(mapping)\n",
    "data_frame.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the new DataFrame\n",
    "Let's see how our transformations have been applied by isolating on a few columns: `df.iloc[rows,[columns]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final = data_frame.iloc[0:12000, [0, 1, 2, 3, 9, 4, 6, 12]]\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the results by PriceType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1 = df_final.groupby([\"PriceTypeD\"])[\"Name\"].count().reset_index(name=\"Count\")\n",
    "df_group1.sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's isolate the top 10 results of our dataframe to keep the top price types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1_top = df_group1.nlargest(10, \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the results by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with WebClient() as api:\n",
    "    df4 = api.metadata_list_values(\"Region\").to_pd_data_frame()[[\"value\", \"description\"]]\n",
    "\n",
    "    # Mapping the Region value to its description\n",
    "    mapping = dict(df4[[\"value\", \"description\"]].values)\n",
    "    df_final[\"RegionD\"] = data_frame.RegionString.map(mapping)\n",
    "\n",
    "    # Applying the grouping\n",
    "    df_group2 = df_final.groupby([\"RegionD\"])[\"Name\"].count().reset_index(name=\"Count\")\n",
    "    df_group2.sort_values(by=\"Count\", ascending=False)\n",
    "df_group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group2 = df_final.groupby([\"RegionD\", \"PriceTypeD\"])[\"Name\"].count().reset_index(name=\"Count\")\n",
    "# df_group2.sort_values(['RegionD','Count'], ascending=False)\n",
    "heatmap = df_group2.loc[\n",
    "    (df_group2[\"RegionD\"] == \"Poland\")\n",
    "    & (\n",
    "        (df_group2[\"PriceTypeD\"] == \"Yield\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Offered\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Price\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Sales\")\n",
    "    )\n",
    "    | (df_group2[\"RegionD\"] == \"United States\")\n",
    "    & (\n",
    "        (df_group2[\"PriceTypeD\"] == \"Yield\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Offered\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Price\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Sales\")\n",
    "    )\n",
    "    | (df_group2[\"RegionD\"] == \"Sweden\")\n",
    "    & (\n",
    "        (df_group2[\"PriceTypeD\"] == \"Yield\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Offered\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Price\")\n",
    "        | (df_group2[\"PriceTypeD\"] == \"Sales\")\n",
    "    )\n",
    "]\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Government Securities Auctions Top by type and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "\n",
    "colours = [\n",
    "    (27 / 255, 54 / 255, 93 / 255),\n",
    "    (37 / 255, 107 / 255, 162 / 255),\n",
    "    (142 / 255, 81 / 255, 168 / 255),\n",
    "    (88 / 255, 162 / 255, 145 / 255),\n",
    "    (205 / 255, 84 / 255, 91 / 255),\n",
    "    (0 / 255, 79 / 255, 89 / 255),\n",
    "    (246 / 255, 141 / 255, 46 / 255),\n",
    "    (0 / 255, 133 / 255, 120 / 255),\n",
    "    (147 / 255, 64 / 255, 84 / 255),\n",
    "]\n",
    "pyplot.bar(df_group1_top[\"PriceTypeD\"], df_group1_top[\"Count\"], color=colours)\n",
    "pyplot.title(\"Pricing Type of Government Securities Auctions\", fontsize=14)\n",
    "pyplot.xlabel(\"PriceType\", fontsize=14)\n",
    "pyplot.ylabel(\"Count\", fontsize=14)\n",
    "pyplot.grid(False)\n",
    "pyplot.autoscale()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the Price Type for Poland and Sweden only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_filtered = df_final.loc[\n",
    "    (df_final[\"RegionD\"] == \"Poland\") | (df_final[\"RegionD\"] == \"Sweden\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = [\n",
    "    (27 / 255, 54 / 255, 93 / 255),\n",
    "    (37 / 255, 107 / 255, 162 / 255),\n",
    "    (142 / 255, 81 / 255, 168 / 255),\n",
    "    (88 / 255, 162 / 255, 145 / 255),\n",
    "    (205 / 255, 84 / 255, 91 / 255),\n",
    "    (0 / 255, 79 / 255, 89 / 255),\n",
    "    (246 / 255, 141 / 255, 46 / 255),\n",
    "    (0 / 255, 133 / 255, 120 / 255),\n",
    "    (147 / 255, 64 / 255, 84 / 255),\n",
    "    (37 / 255, 40 / 255, 42 / 255),\n",
    "    (51 / 255, 63 / 255, 72 / 255),\n",
    "    (103 / 255, 109 / 255, 114 / 255),\n",
    "    (199 / 255, 201 / 255, 199 / 255),\n",
    "    (239 / 255, 240 / 255, 241 / 255),\n",
    "]\n",
    "df_final_filtered.groupby([\"RegionD\", \"PriceTypeD\"]).size().unstack().plot(\n",
    "    kind=\"bar\", stacked=True, color=colours\n",
    ")\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f07703081b087c011f489eea73b431cab9a444b9d10d39f2f152d47c6ed00d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
